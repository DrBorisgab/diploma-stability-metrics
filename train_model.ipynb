{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f78TZl3gIH2b"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMlMwL6XIGEp"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "import random\n",
        "import glob\n",
        "import seaborn as sns\n",
        "from inference.py import *\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import pytorch_lightning as pl\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.utils.losses import JaccardLoss\n",
        "from segmentation_models_pytorch.utils.metrics import IoU\n",
        "import warnings\n",
        "import networkx as nx\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "pl.seed_everything(0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import rasterio\n",
        "from aeronet_vector import FeatureCollection, Feature\n",
        "import shapely\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from dlutils.data import markup_generation, fcutils, angleutils, heightutils, markup_generation\n",
        "from dlutils.utils import visualization, npfile_utils\n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from inference.py import *\n",
        "from stability_metrics.py import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare data train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20114/20114 [21:12<00:00, 15.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train contains 12460 images and 12460 masks\n",
            "val contains 1614 images and 1614 masks\n",
            "test contains 1518 images and 1518 masks\n"
          ]
        }
      ],
      "source": [
        "img_paths = sorted(glob.glob('samples_new\\\\*\\images\\*.tif'))\n",
        "Path(img_paths[0]).stem\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "from tqdm.auto import trange\n",
        "img_paths = sorted(glob.glob('samples_new\\\\*\\images\\*.tif'))\n",
        "mask_paths = sorted(glob.glob('samples_new\\\\*\\masks\\*.tif'))\n",
        "\n",
        "for i in trange(len(img_paths)):\n",
        "\n",
        "    mask = Image.open(mask_paths[i])\n",
        "    if ToTensor()(mask).sum() > w * h * 0.05:\n",
        "        \n",
        "        w, h = img.size\n",
        "        img = Image.open(img_paths[i])\n",
        "\n",
        "        if np.random.rand() < 0.8:\n",
        "            dataset = 'train'\n",
        "        elif np.random.rand() < 0.5:\n",
        "            dataset = 'val'\n",
        "        else:\n",
        "            dataset = 'test'\n",
        "\n",
        "        save_image(ToTensor()(img), f'samples_cheater/{dataset}/images/' + Path(img_paths[i]).name)\n",
        "        save_image(ToTensor()(mask), f'samples_cheater/{dataset}/masks/' + Path(mask_paths[i]).name)\n",
        "\n",
        "for dataset in ['train','val','test']:\n",
        "    masks_len = len(glob.glob(f'samples_cheater/{dataset}/masks/*.tif'))\n",
        "    imgs_len =  len(glob.glob(f'samples_cheater/{dataset}/images/*.tif'))\n",
        "    print(f\"{dataset} contains {imgs_len} images and {masks_len} masks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_if_needed(img, sample_size):\n",
        "    old_size = img.size\n",
        "\n",
        "    x_size = (int(old_size[0] / sample_size[0]) + 1)*sample_size[0] if old_size[0] % sample_size[0] != 0 else old_size[0]\n",
        "    y_size = (int(old_size[1] / sample_size[1]) + 1)*sample_size[1] if old_size[1] % sample_size[1] != 0 else old_size[1]\n",
        "    new_size = (x_size, y_size) \n",
        "\n",
        "    if new_size == old_size:\n",
        "        return img\n",
        "    new_img = Image.new(img.mode, new_size, 0)\n",
        "    new_img.paste(img, (int((new_size[0]-old_size[0])/2),\n",
        "                        int((new_size[1]-old_size[1])/2)))\n",
        "        \n",
        "    return new_img\n",
        "\n",
        "def crop_samples(img, sample_size):\n",
        "    \n",
        "    img = pad_if_needed(img, sample_size)\n",
        "    x_samples = img.size[0]//sample_size[0]\n",
        "    y_samples = img.size[1]//sample_size[1]\n",
        "\n",
        "    samples = []\n",
        "    ss = sample_size\n",
        "    for i in range(x_samples):\n",
        "        for j in range(y_samples):\n",
        "            sample = img.crop((i*ss[0], j*ss[0], (i+1)*ss[0], (j+1)*ss[1]))\n",
        "\n",
        "            samples.append(np.array(sample, dtype=np.float32)) # сделали dtype=np.float32 чтобы маски из булевого типа перевести во флоат\n",
        "\n",
        "    return samples\n",
        "\n",
        "sample_size = (512,512)\n",
        "\n",
        "img_paths = sorted(glob.glob('samples\\***\\\\rgb.tif'))\n",
        "mask_paths = sorted(glob.glob('samples\\***\\900.tif'))\n",
        "\n",
        "for i in range(len(img_paths)):\n",
        "\n",
        "    images, masks = [], []\n",
        "\n",
        "    img = Image.open(img_paths[i])\n",
        "    mask = Image.open(mask_paths[i])\n",
        "\n",
        "\n",
        "    images.extend(crop_samples(img,sample_size))\n",
        "    masks.extend(crop_samples(mask,sample_size))\n",
        "\n",
        "    \n",
        "    for j in range(len(images)):\n",
        "        \n",
        "        if masks[j].sum() != 0:  # проверка перед сохранением на пустую маску только для теста и вала\n",
        "            print(img_paths[i][15:16]+ '_'+ str(j+1)) # 9:11 20:22 15:17\n",
        "            print(ToTensor()(masks[j]).shape, ToTensor()(images[j]/255).shape)\n",
        "            save_image(ToTensor()(images[j]/255), 'samples_new/train/images/' + img_paths[i][15:17]+ '_'+ str(j+1) + '.tif')\n",
        "            save_image(ToTensor()(masks[j]), 'samples_new/train/masks/' + mask_paths[i][15:17] + '_'+ str(j+1) + '.tif')\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCQSKxQSIwc8"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean = [0.253317  , 0.26740879, 0.23025433]\n",
        "std  = [0.15158384, 0.14880167, 0.14123519]\n",
        "\n",
        "train_augs = A.Compose([\n",
        "    # A.Flip(p=0.5),\n",
        "    # A.Rotate(border_mode=0, p=0.8),\n",
        "    # A.RandomScale(scale_limit=0.2, p=0.5),\n",
        "    A.RandomBrightness(limit=0.2, p=0.2),\n",
        "    A.RandomContrast(limit=0.2, p=0.2),\n",
        "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.2),\n",
        "    A.Normalize(mean=mean, std=std, max_pixel_value=255.0, always_apply=True),\n",
        "    A.PadIfNeeded(512,512, border_mode=0),    \n",
        "    A.CenterCrop(512,512, always_apply=True),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_augs = A.Compose([\n",
        "    A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
        "    ToTensorV2(p=1.0)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r8FDx3NJNCw"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_evp-CCQJMki"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'SAVE_DIR': 'E:/diplom_dataset/samples_cheater/',\n",
        "    'run_name': str(datetime.now()),\n",
        "    'project_name': 'unet_resnet34_2024',\n",
        "    'augs_type' : 'color_augs',\n",
        "    'epochs': 20, \n",
        "    'sample_size': (512,512),\n",
        "    'batch_size': 8,\n",
        "    'num_workers': 0, #2\n",
        "    # 'num_samples': 1500,\n",
        "    'lr': 5e-5,#, 1e-4,\n",
        "    'use_tpu': False,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJMk8bQkK1rd",
        "outputId": "3c0f594b-d99c-449a-a4c0-6482644c62b2"
      },
      "outputs": [],
      "source": [
        "dm = PlDataModule(data_dir = CFG['SAVE_DIR'],\n",
        "                  train_aug=train_augs, \n",
        "                  val_aug=val_augs,\n",
        "                  batch_size=CFG['batch_size'], #1\n",
        "                  num_workers=CFG['num_workers'], \n",
        "                  use_tpu=CFG['use_tpu'], \n",
        "                  train_dset_mode='full', \n",
        "                  cpAug=False)\n",
        "\n",
        "dm.setup()\n",
        "\n",
        "train_loader = dm.train_dataloader()\n",
        "val_loader = dm.val_dataloader()\n",
        "\n",
        "len(train_loader), len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WgbImChJcnD"
      },
      "outputs": [],
      "source": [
        "unet = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\")\n",
        "\n",
        "#model_name = 'unet34_20_8_0_5e-05_w_strct_augs'\n",
        "#model = ModelPl.load_from_checkpoint('unet_resnet34/'+ model_name +'.ckpt')\n",
        "\n",
        "model = ModelPl(unet, JaccardLoss(), lr=CFG['lr'])\n",
        "\n",
        "save_path = CFG['SAVE_DIR']+CFG['run_name']\n",
        "\n",
        "#  pip install -U 'wandb>=0.12.10'\n",
        "wandb_logger = pl.loggers.WandbLogger(name=CFG['run_name']+'_'+str(CFG['epochs'])+'_'+str(CFG['batch_size']), \n",
        "                                      project=CFG['project_name'],\n",
        "                                      config = CFG,\n",
        "                                      config_exclude_keys = ['SAVE_DIR','run_name''project_name','use_tpu']\n",
        "                                      #group = 'with_aug',\n",
        "                                      )\n",
        "callback = pl.callbacks.ModelCheckpoint(monitor='val IoU',save_top_k=1, \n",
        "                                        # dirpath=CFG['SAVE_DIR'],\n",
        "                                        #filename=CFG['run_name'],\n",
        "                                          mode='max')\n",
        "#wandb.config(CFG)\n",
        "trainer = pl.Trainer(#gpus = 1, \n",
        "                     #precision = 16,\n",
        "                     accelerator='gpu',\n",
        "                     max_epochs = CFG['epochs'], \n",
        "                     logger = wandb_logger,\n",
        "                     enable_progress_bar=True,\n",
        "                     #progress_bar_refresh_rate = 2,\n",
        "                     # callbacks = callback,\n",
        "                     #callbacks = [TQDMProgressBar(refresh_rate=1)],\n",
        "                     num_sanity_val_steps=0\n",
        "                     #accumulate_grad_batches=2,\n",
        "                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_dy9dWwurql"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, train_loader, val_loader)\n",
        "trainer.save_checkpoint('unet_resnet34/unet34_'+ str(CFG['epochs']) + '_'+ str(CFG['batch_size']) + '_'+ str(CFG['num_workers']) +'_'+ str(CFG['lr']) +'_w_less_color_augs.ckpt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
