{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "import os\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(0)\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import imgaug\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.utils.losses import JaccardLoss\n",
    "from segmentation_models_pytorch.utils.metrics import IoU\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from pathlib import Path\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm.auto import trange\n",
    "from scipy.stats import f_oneway, kruskal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.py import *\n",
    "from stability_metrics.py import *\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.253317  , 0.26740879, 0.23025433]\n",
    "std  = [0.15158384, 0.14880167, 0.14123519]\n",
    "\n",
    "test_augs = A.Compose([\n",
    "    # A.Flip(p=0.5),\n",
    "    # A.Rotate(border_mode=0, p=0.5),\n",
    "    A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "    A.RandomBrightness(limit=0.5, p=0.8),\n",
    "    A.RandomContrast(limit=0.5, p=0.8),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.8),\n",
    "    #A.Normalize(mean=mean, std=std, max_pixel_value=255.0, always_apply=True),\n",
    "    A.PadIfNeeded(512,512, border_mode=0),    \n",
    "    A.CenterCrop(512,512, always_apply=True),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_augs = A.Compose([\n",
    "    A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0)\n",
    "])\n",
    "\n",
    "\n",
    "contrast = np.load('E:/diplom_dataset/samples_cheater/test/contrast1.npy')\n",
    "brightness = np.load('E:/diplom_dataset/samples_cheater/test/brightness1.npy')\n",
    "hue = np.load('E:/diplom_dataset/samples_cheater/test/hue.npy')\n",
    "angles = np.load('E:/diplom_dataset/samples_cheater/test/angles.npy')\n",
    "scale_ = np.load('E:/diplom_dataset/samples_cheater/test/scale_.npy')\n",
    "\n",
    "# choose distortions\n",
    "torchvision_transform = {\n",
    "                        # transforms.functional.adjust_contrast:contrast,\n",
    "                        # transforms.functional.adjust_brightness:brightness,\n",
    "                        #transforms.functional.adjust_hue:hue\n",
    "                        transforms.functional.rotate:angles,\n",
    "                        scale:scale_\n",
    "                        }\n",
    "\n",
    "batch_siZe = 10 #50\n",
    "orig_dataloader = get_test_dataloader('E:/diplom_dataset/samples_cheater/test/', val_augs, batch_siZe, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Метрика зависящая от ground truth (Сравниваем значение метрик качества)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'unet34_20_8_0_5e-05_w_less_color_augs'\n",
    "model_names = ['unet34_20_8_0_5e-05', 'unet34_20_8_0_5e-05_w_strct_augs']\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = ModelPl.load_from_checkpoint('unet_resnet34/'+ model_name +'.ckpt')\n",
    "    Predictor = SimplePredictor(model.cuda(), device=device, \n",
    "                                sample_size=(512,512), \n",
    "                                #sample_size=(1024,1024), \n",
    "                                pad_size=64)\n",
    "    scores = calculate_metrics(Predictor, 'E:/diplom_dataset/samples_cheater/test', \n",
    "                            augs=val_augs, \n",
    "                            augs_dict = torchvision_transform,\n",
    "                            threshold=0.5)\n",
    "\n",
    "    df = pd.DataFrame(pd.DataFrame(scores))\n",
    "    print(df)\n",
    "    df.to_csv('metrics/files/augs_struct_img_'+ model_name +'.csv', index=False) \n",
    "    #df.to_csv('metrics/files/orig_img_'+ model_name +'.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_1 = 'unet34_20_8_0_5e-05'         \n",
    "#model_name_2 =  'unet34_20_8_0_5e-05_w_color_augs'   \n",
    "#model_name_2 = 'unet34_20_8_0_5e-05_w_less_color_augs'\n",
    "model_name_2 = 'unet34_20_8_0_5e-05_w_strct_augs'\n",
    "metric_name = 'IoU'\n",
    "\n",
    "print(superwised_metrics(model_name_1,metric_name))\n",
    "print(superwised_metrics(model_name_2,metric_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Метрики не зависящие от ground truth\n",
    "\n",
    "Сравниваем результаты моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image with augs\n",
    "plt.imshow(scale(next(iter(orig_dataloader))['mask'], 0.5)[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all augs\n",
    "iou = IoU() \n",
    "mae_f = torch.nn.L1Loss(reduction='none')\n",
    "mse_f = torch.nn.MSELoss(reduction='none')\n",
    "@torch.no_grad()\n",
    "\n",
    "# ['unet34_20_8_0_5e-05', 'unet34_20_8_0_5e-05_w_less_color_augs',\n",
    "model_names = ['unet34_20_8_0_5e-05', 'unet34_20_8_0_5e-05_w_strct_augs']  \n",
    "\n",
    "\n",
    "torchvision_transform_color = {transforms.functional.adjust_contrast:contrast,\n",
    "                                transforms.functional.adjust_brightness:brightness,\n",
    "                                #transforms.functional.adjust_hue:hue\n",
    "                                }\n",
    "torchvision_transform_struct = {transforms.functional.rotate:angles,\n",
    "                        scale:scale_}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = ModelPl.load_from_checkpoint('unet_resnet34/'+ model_name +'.ckpt').cuda()\n",
    "    print(model_name, loader_metircs(model, orig_dataloader=orig_dataloader, augs_dict = torchvision_transform_color, threshold=0.501))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow predict\n",
    "model = ModelPl.load_from_checkpoint('unet_resnet34/unet34_20_8_0_5e-05.ckpt').cuda()\n",
    "img = next(iter(orig_dataloader))['img']\n",
    "img_augs = transforms.functional.adjust_contrast(img,contrast[0]).cuda()\n",
    "pred_augs = model(img_augs)\n",
    "plt.imshow(pred_augs[0].T.detach().cpu()) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Test on prod models (buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final\n",
    "\n",
    "architectures: Final[dict] = {'Unet': smp.Unet,\n",
    "                              'Unet++': smp.UnetPlusPlus,\n",
    "                              'MAnet': smp.MAnet,\n",
    "                              'DeepLabV3+': smp.DeepLabV3Plus}\n",
    "\n",
    "encoders: Final[dict] = {'mit-b2': 'mit_b2',\n",
    "                         'mit-b3': 'mit_b3',\n",
    "                         'efficientnet-b1': 'efficientnet-b1',\n",
    "                         'efficientnet-b2': 'efficientnet-b2',\n",
    "                         'efficientnet-b3': 'efficientnet-b3',\n",
    "                         'efficientnet-b4': 'efficientnet-b4',\n",
    "                         'efficientnet-b5': 'efficientnet-b5',\n",
    "                         'timm-res2net50-26w-4s': 'timm-res2net50_26w_4s'}\n",
    "\n",
    "models_root = 'D:\\diploma\\cv-corruption-research\\models'\n",
    "model_names = ['DeepLabV3+_efficientnet-b4' , 'MAnet_efficientnet-b4', 'Unet_mit-b2', \n",
    "                'Unet++_efficientnet-b5']\n",
    "\n",
    "model_name = model_names[0]\n",
    "\n",
    "segm_arch = model_name.split('_')[0]\n",
    "encoder = model_name.split('_')[1]\n",
    "\n",
    "model = architectures[segm_arch](in_channels = 3, classes=4, \n",
    "                                 encoder_name = encoders[encoder],\n",
    "                                 encoder_weights=None,\n",
    "                                 activation = None)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(models_root, f'{model_name}.pth')))\n",
    "model.cuda()\n",
    "model.eval();\n",
    "print(model)\n",
    "#next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_metircs(model, orig_dataloader=orig_dataloader, augs_dict = torchvision_transform, threshold=0.501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open images and count metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataloader = get_test_dataloader('E:/diplom_dataset/samples_cheater/test/', val_augs, 1, num_workers=0)\n",
    "batch = next(iter(orig_dataloader))\n",
    "\n",
    "i, j  = 0, 0\n",
    "img_orig = batch['img'].cuda()\n",
    "\n",
    "img_augs = img_orig.clone().detach()\n",
    "\n",
    "\n",
    "for k in range(len(img_orig)):\n",
    "    #print(k)\n",
    "    for function, parameters in torchvision_transform.items():\n",
    "        img_augs[k] = function(img_augs[k], parameters[i])  \n",
    "        #print('i', i, function, parameters)             \n",
    "    i+=1\n",
    "\n",
    "\n",
    "pred_orig = model(img_orig).sigmoid() \n",
    "pred_augs = model(img_augs).sigmoid() \n",
    "\n",
    "for k in range(len(img_orig)):\n",
    "    for function, parameters in torchvision_transform.items():\n",
    "        if function in [transforms.functional.rotate]:\n",
    "            pred_orig[k] = function(pred_orig[k], parameters[j])\n",
    "    j+=1\n",
    "\n",
    "mape_ = mape_f(pred_orig, pred_augs).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Test on prod models (forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image with augs\n",
    "\n",
    "model = torch.load('forest\\model07.pt')\n",
    "\n",
    "img = next(iter(orig_dataloader))['img']\n",
    "img_augs = transforms.functional.adjust_hue(img.int(), contrast[0])\n",
    "\n",
    "pred_orig = model(img.cuda())\n",
    "pred_orig = pred_orig.sigmoid()\n",
    "plt.imshow(pred_orig[0].T.cpu()) \n",
    "plt.show()\n",
    "\n",
    "pred_augs = model(img_augs.cuda())\n",
    "pred_augs = pred_augs.sigmoid()\n",
    "plt.imshow(pred_augs[0].T.cpu()) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = IoU() \n",
    "mae_f = torch.nn.L1Loss(reduction='none')\n",
    "mse_f = torch.nn.MSELoss(reduction='none')\n",
    "@torch.no_grad()\n",
    "\n",
    "for model_name in ['forest\\model07.pt',\n",
    "                   'forest\\model08.pt',\n",
    "                   'forest\\model09.pt']:\n",
    "    model = torch.load(model_name)\n",
    "    print(model_name)\n",
    "    print(loader_metircs(model, orig_dataloader=orig_dataloader, augs_dict = torchvision_transform, threshold=0.501))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rotate predict mask for predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_augs = A.Compose([\n",
    "    ToTensorV2(p=1.0)\n",
    "])\n",
    "\n",
    "img_paths = sorted(glob.glob('E:/diplom_dataset/samples_cheater\\\\test\\images\\*.tif'))\n",
    "mask_paths = sorted(glob.glob('E:/diplom_dataset/samples_cheater\\\\test\\masks\\*.tif'))\n",
    "\n",
    "angles = np.load('E:/diplom_dataset/samples_cheater/test/angles.npy')\n",
    "\n",
    "for i in trange(len(img_paths)):\n",
    "    image=Image.open(img_paths[i])\n",
    "    mask=Image.open(mask_paths[i])\n",
    "\n",
    "    image = np.array(torchvision.transforms.functional.rotate(image, angles[i]))\n",
    "    mask = np.array(torchvision.transforms.functional.rotate(mask, angles[i]))[:,:,0]\n",
    "\n",
    "    trans = save_augs(image=image, mask=mask)\n",
    "    img, mask = trans['image'], trans['mask']\n",
    "    save_image(img.float()/255, f'E:/diplom_dataset/samples_cheater/test/images/' + Path(img_paths[i]).name)\n",
    "    save_image(mask.float(), f'E:/diplom_dataset/samples_cheater/test/masks/' + Path(mask_paths[i]).name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save test dataset with augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1518/1518 [00:30<00:00, 50.39it/s]\n"
     ]
    }
   ],
   "source": [
    "img_paths = sorted(glob.glob('E:/diplom_dataset/samples_cheater\\\\test\\images\\*.tif'))\n",
    "mask_paths = sorted(glob.glob('E:/diplom_dataset/samples_cheater\\\\test\\masks\\*.tif'))\n",
    "\n",
    "for i in trange(len(img_paths)):\n",
    "    trans = test_augs(image=np.array(Image.open(img_paths[i])), mask=np.array(Image.open(mask_paths[i]))[:,:,0])\n",
    "    img, mask = trans['image'], trans['mask']\n",
    "    save_image(img.float()/255, f'E:/diplom_dataset/samples_cheater/test_color_augs_l/images/' + Path(img_paths[i]).name)\n",
    "    save_image(mask.float(), f'E:/diplom_dataset/samples_cheater/test_color_augs_l/masks/' + Path(mask_paths[i]).name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
